# 23. Agentic AI ROI: From Automation to Decisions

**Video ID:** PH6KNZykjX4
**Channel:** SiliconANGLE theCUBE
**Duration:** 40:57
**URL:** https://www.youtube.com/watch?v=PH6KNZykjX4

**Module:** Case Studies & Lessons
**Module Rationale:** The video heavily features real-world examples from DoozerAI's deployments, specific customer cases like the financial reporting agent, and practical lessons learned from actual enterprise implementations

## Summary
- Agentic AI represents a shift from content generation to reasoning, decision-making digital co-workers that collaborate in business workflows
- 61% of enterprises plan to deploy AI agents within 18 months, with 73% investing significantly in AI reasoning and decision intelligence capabilities
- Trust emerges as the primary barrier to adoption - only 49% of AI professionals have high trust in agents for decision-making tasks
- DoozerAI's approach focuses on anthropomorphizing agents with names and email addresses to bridge cultural gaps in organizations
- Successful agent deployment requires running systems in parallel with human workers initially, then gradually reducing oversight as trust builds
- The investment shift moves from generative AI as the end goal to using LLMs as foundational gateways for building more sophisticated agent capabilities
- Organizations should avoid 'agent sprawl' by using unified platforms rather than deploying multiple disconnected agents from different vendors
- Real-world success requires focusing on reliability, robustness, and explainability rather than just technical capabilities
- The transition from task automation to knowledge worker augmentation represents a fundamental shift from IT projects to labor market transformation

## Key Takeaways
- **DO:** Start small with agent deployments, run them in parallel with human workers, and gradually reduce oversight as trust builds over time
- **DO:** Focus on explainability and observability - agents must be able to show their reasoning and decision-making process to build trust
- **DO:** Use unified agent platforms rather than deploying multiple disconnected agents to avoid 'agent sprawl' and maintain centralized oversight
- **DO:** Invest in cross-functional integration involving both IT and business teams, treating this as organizational change management
- **DON'T:** Don't try to build agents entirely in-house - the MIT study shows higher failure rates compared to using platforms or external expertise
- **DON'T:** Don't deploy agents that can be easily persuaded or change decisions based on user pressure - maintain consistent, reliable decision-making

## Topics
agentic_ai, digital_workers, trust_in_ai, decision_intelligence, ai_reasoning, enterprise_adoption, agent_platforms

## Key Moments
- [04:05](https://www.youtube.com/watch?v=PH6KNZykjX4&t=245s): Paul describes building the first email agent for insurance recodes at Allstate, demonstrating early agentic AI success
- [13:23](https://www.youtube.com/watch?v=PH6KNZykjX4&t=803s): Survey data reveals 61% of enterprises plan agent deployment in 18 months, showing significant market momentum
- [19:33](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1173s): 73% of organizations investing significantly in AI reasoning and decision intelligence capabilities over next 18 months
- [29:46](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1786s): Trust data shows only 49% have high confidence in agents for decision-making, identifying the key adoption barrier
- [36:58](https://www.youtube.com/watch?v=PH6KNZykjX4&t=2218s): Final advice on starting small but thinking big, emphasizing integration over just innovation

## Presentation Slides
*4 unique slides extracted from this video*

### Slide at [20m14s](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1214s)

7 3  0 Yi                                                      Q  How would you describe your organization's level of investment
0                                                       in Al reasoning & decision intelligence over the next 18 months?
of enterprises plan
major investments                                 Significant ~ multiple funded programs  Ps 37%
in AI agents that
can reason                                                         Strategic - core to our enterprise strategy  | 36%
Moderate — funding a few use cases                               21%
Minimal - exploratory funding only        4%
thecuse
eg research
Sodinatint NY
“Ws                                                                        No investment planned 2%
Agentic Al
FUTURES INDEX                                              N=625
==           5          =          ?                      ]           |          |           |           4          \                       aie          s            __ Confidential. Terms apply.

### Slide at [24m06s](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1446s)

= ie ar ee ee ee ee    |    ae ee ee
6 2    Y/ 0                                        Q   What are the primary activities that you envision
Envision a shift                                  your organization’s AI Agents performing
to judgment-based
Help automate routine or repetitive tasks  PY 67%
agents that can
help humans make               Help diagnose & solve business problems YT ti‘éiS
better decisions
Assist in making better decisions  PY 62%
~&:                          Act autonomously on behalf of workers es ::
Agentic Al
FUTURES INDEX                                               N=625

### Slide at [29m44s](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1784s)

fe)   |     4 9 0/                          Q Which of the following activities do you have high
n  Y                                                confidence that Al agents can perform accurately?
Trust AI agents
Plan - formulate a logical
to make accurate and                ee
trustworthy decisions
Solve problems - diagnose issues, identify   LC 7
root causes, and recommend solutions.
Make decisions ~ evaluate multiple fr 49%
actions and choose the most effective ones                                                                               °
Explain thei     ing — it       ‘that
Act auto}   ly - takin;  iT  ithe
Agentic AI              Tae
FUTURES INDEX
N=625
aa     ———   =   —7   }.   |   |   |   |   \   \   .—\   =   =  Confidential. Terms apply. —

### Slide at [32m50s](https://www.youtube.com/watch?v=PH6KNZykjX4&t=1970s)

INVESTMENT                           USE CASES                                 TRUST
Al Reasoning                              Knowledge Work                           No Trust, No ROI
Kn "Ny                  a /                   ly
;      3.7   A          Fa    31 /      A           ;  oa \          g
/ #      ' @       @
ZB iweste1 Agentic Al Technology Indices
= The vast majority envision a higher ROI than GenAI can deliver alone.
=: The shift beyond task automation to AI decision-making is underway.
= Trust has emerged as the currency of innovation
ai           at       f   ,    ]    1    i    t    c        "§           Confidential. Terms apply>—


## TL;DR
Trust is the currency of agentic AI ROI - start small, prove reliability, then scale decision-making capabilities.

## Full Transcript

>> Hello, and welcome back
to the Next Frontiers of AI podcast where we explore
the real-world strategies and success stories that
are shaping the future of enterprise AI.
I'm Scott Hebner, your host and principal analyst at theCUBE Research.
Thanks so much for tuning in.
As we've been discussing
throughout this series, we are entering a new
golden age of AI agents, a new super cycle of innovation.
And while generative AI has
dominated the early headlines, I think the real story now
is the shift to agentic AI, digital co-workers that
go beyond creating content and automating tasks
to actually reasoning, making decisions, and
collaborating in the flow of work.
That's why I'm so excited to share today new findings
from the Agentic AI Futures Index.
This survey indicates that the number of companies deploying AI
agents will scale significantly over the next 18 months, as will the investment priorities
shift towards focusing on

[01:02]
enabling reasoning and
decision-making capabilities.
The message is quite clear: The focus has shifted from
demonstrating generative AI's potential in delivering
tangible ROI through agents that can now act as knowledge
workers and decision makers.
This is driving generative AI and LLMs from being the
main focus of investment to becoming the foundational
gateway to AI with a new layer of innovation capabilities
rolling out rapidly on top of it.
Yet, the barriers are quite clear, as we found in our survey.
The transition from
aspirations to strategy to execution continues to be highly challenging, to say the least.
And at the very top of the list is trust.
Trust is emerging as the
currency of innovation.
No trust, no ROI.
So joining me to unpack all this and share real-world lessons
from deploying AI agents in real business settings is Paul Chada.

[02:03]
He's the CEO and founder of DoozerAI.
Paul has been on the front
line selling, building, and scaling AI agents that deliver measurable
business outcomes, is one of the most thoughtful and insightful influencers
in the public discourse around agentic AI.
And you should be following
him if you're not.
But let me bring Paul
up on the screen here and welcome you to the
show. Thanks for being here.
>> Thanks, Scott. Thanks
for the nice, warm welcome.
>> So where are you, by the way?
>> So I'm based here about 10 minutes south of Irvine in California.
People always listen to my accent and think, "Where is he originally from?
2 So I was born and raised in Ireland and came to California in 2013 with my family.
>> That's awesome. So
you've been in California?
I've been on the other side of the coast forever in Connecticut and in New York area where,
by the way, it's going to be 80 degrees tomorrow, so...
>> Oh my goodness. Yeah, no.

[03:03]
>> Winter was coming, and now I guess this is
what you call Indian Summer.
Yeah. Anyhow, so Paul, let's start with talk a little bit about you.
Tell us your personal journey,
how you founded Doozer.
ai, and what shaped your
point of view on the state of ROI in the enterprise.
>> Okay. Thanks, Scott. Yeah.
So believe it or not, I originally
studied AI at Edinburgh University in college.
And then I went into the automation space.
So my first job was actually working on a team building
an automation platform, but it ended up being a Gartner-rated BPM and case management platform.
And by that stage, when it was acquired by a California company, I was over here.
I was in enterprise sales and did that for quite a successful career for about five years.
And then I left to join a
startup to build a new low- code platform.

[04:05]
And while I was doing R&D for that, GPT- 3 was out and we started experimenting.
I started working with an ex-colleague and friend, Gavin, who came.
And we started seeing that using these LLM models
not only could it generate great emails and content,
but it actually could...
Coupled with some of the integration that we built in the past, we realized that it could actually reach
some of these hard-to-reach ROI use cases that
previously had been sort of untouchable.
And so that's why we decided to build...
And, actually, before we started to build a
platform, we originally built an email agent for doing insurance recodes, and we
demoed it to Allstate Insurance.
It was very simple.
Well, it was complex back
then, but it seems simple now.
And it was basically you
just mail your quote into

[05:06]
an email address and the agent
would automatically read all the information, hit the reading engine, and then recode it for you the same way a
person would've done.
And what we realized was,
well, the person sending it in, they think there's a person
on the other side of that.
They don't realize that it's an AI agent.
And so we thought, "Well,
what if we built out the capabilities behind that
to allow organizations to build all the capabilities
required to actually accomplish those knowledge worker tasks, then we could package them up and actually provide them as
off-the-shelf capabilities." >> Yeah, I think we first talk...
I don't know. It was
maybe nine months ago.
I remember it was really cold
and snowy here in Connecticut.
But I think it was back in
the beginning of the year.
And the one thing that
really struck out to me was when I went to your website Doozer.
ai, it sort of reminded me of Indeed or LinkedIn jobs where you're going out and you had a list of
all these agents to hire

[06:07]
and they had names and what kind of a worker are you looking for.
And I think you were on the
early fringe of that, for sure, because I didn't see too many
of them back at that time when the technology
was just starting to...
People talk about agentic
and the idea of AI agents, and it was pretty cool.
>> Yeah. No, thank you.
Part of it was sort of trying
to bridge that cultural gap in an organization of people wanting to work alongside digital agents.
And so we thought giving them names and...
clearly, if they have email
addresses, then you have a way to communicate with them.
And obviously you've Slack
and Teams now as well.
But if instead of it being productized like
it's a data entry system or it's an accounts payable
system, we thought, "Well, I just need my invoice processed," or, "I need my expense claim done, and therefore I'm just going to
email it to Sally in accounts," or, "I'm going to email it
to Emily at another company.

[07:11]
" And so by trying to sort
of amorthrophize these capabilities, it just makes it
a bit more approachable in an enterprise setting, you know?
>> Yeah. And I think you
were on, I think, again, the leading edge also of
this notion of digital labor, digital labor transformation.
Which my podcast, the
podcast we did last week, was all about the digital- >> Yes.
- ...
labor transformation index was one of our surveys that we've been doing.
We doing a lot of surveys
recently, 625 people.
And clearly, digital labor is inevitable.
I think it was 90-percent-plus of these respondents
basically said that they agree with the statement that today's
leaders will be the last ones to manage a human-only
workforce, right?
>> Yeah. - And so I think
we're well on our way that...
You know, this isn't just
about technology and automation and helping people get things done faster.

[08:14]
It's not about the IT department, it's about the labor market, which is...
By the way, labor expense is about 60% of the average enterprise's expense.
So if you can give superpowers to your teams and get more done and...
Not just more done, but
get things done better with better decisions, and
better problem solving, and better root cause analysis of problems and be able to look at emerging
trends more effectively...
I mean, it's going to
be hard to measure that, but the ROI is profoundly
bigger than what we just went through over the last many
years around generative AI and getting tasks done
better and faster, right?
>> Yeah. Yeah. In my mind, there's sort of two ways look at this.
One is the knowledge
worker in organizations, they're already using
ChatGPT to great advantage.
They know how to use ChatGPT
to make their job easier.
And so they're doing that.
There's a little bit of kind of a shadow industry where they're...

[09:15]
Without their employer knowing
they're actually using it to help their job and make their decisions better and faster.
And then, the other thing where
the angle we come at it is, well, we take those automations that are going into ChatGPT, and we put them into agent flows.
And we encapsulated it
within an idea of an agent that's then going to work
alongside the knowledge worker to basically hide off a lot of
the hard work of being able to maybe read documents,
look at pictures, look at...
sort of bubble up the
decision-making, as it were, to the human being.
And, eventually, of course,
you're going to have situations where then you're hands-off
and you let the knowledge...
you let the digital worker
completely autonomously take action and do that because you've seen it
make the correct decision so many times that you now trust it.

[10:17]
And I think right now we're
in that sort of phase where organizations are just
wanting to run it in parallel.
And I think as an organization
at DoozerAI, we see that's the best example: build
an agent, run it in parallel with your existing workforce, and then you can sort of ease up on the human oversight over time.
And the best example of that is we have financial reporting agent.
And I'd say, I joke with other people, it took us probably a week and a half to build, to build the agent, to have all the capabilities
and crunch the numbers and get the information
from the different systems.
But we probably... No, not probably.
We did run it for at least a month.
Because over that course of
a month, there were different situations that arised.
The goals changed during the
month, "Okay, we need an agent to be able to respond to changing goals.
" Maybe there was the second week in the

[11:19]
month something else happens.
"Okay, the agent needs
to accommodate that.
"
And I think successful agents that get deployed are the ones that are the least brittle.
You need reliability, you need robustness, and you need that sort of dependability so that people will accept them, otherwise the agent's just going to...
It'll be a shiny new object,
and it'll be cast aside.
So for us, it's all about adoption and reliability.
>> Yeah. I agree with you.
And I think underneath all that is the trust element.
And also, one of my
predictions back in January for this year, without going
off the details of it, was that generative AI, LLMs,
were going to turn out to be like the browser wars
of the early internet age where they were the main
focus of attention, most- >> Yeah, more...
- ...
critical decision you can ever make.
But it turned out that was how you built around the browser is
where the ROI came from.

[12:21]
And I think the same thing is true with generative AI, right?
And like you said, it's
a foundational capability that you didn't build
around with the agents and additional automations
and all these new technologies that are coming on the scene.
And there's a lot to do
in the years ahead here.
I'm going to show you a chart
here in a second on just where we are from our
Agentic AI Futures Index on where the state of
adoption is for agentic AI.
And then from your perspective
at Doozer, I'm curious to what you see driving this acceleration and are these organizations
really prepared to move beyond pilots and experimentation
to real deployment with real workers at their side?
Let me just kind of explain
this one chart here.
So the Agentic AI Futures Index,
fresh data from September.
625 pre-qualified AI business and tech leaders.

[13:23]
So they're involved with AI
projects in their company.
61 questions, nine different job titles, 13 industries.
So we asked a pretty good panel here that makes this increasingly
statistically valid.
But it was 61% said that they plan to deploy AI agents over the next 18 months.
55% are working on them now.
It goes to 61% if you went
out over the full 18 months.
So, clearly, there is a shift.
That's a pretty good number for this early in the cycle, I think.
>> Yeah. No, definitely is.
I mean, there's a couple
of things behind that.
One, there's a lot of
executives out there who are saying they're doing
agents or using agents or deploying them for the
shareholder and for the board because they're being forced.
They're being asked, "What
are you doing with AI?
You need to be doing something with AI.
" But the ones who are actually
rolling their sleeves up

[14:25]
and doing the great work
of deploying agents, I think they're taking a very
measured approach for the ones that are actually going live.
They're choosing some of the easy wins to get the technology in place, right?
And so some of those- >> Yeah.
>> Some of those I wouldn't
classify as really agentic.
They're not quite autonomous.
However, they are automation
using LLMs, and that's okay.
I think it's fine to just
get the technology in place, the infrastructure,
understand what it's good at and what it's not good at,
and then build on that.
And I think through that and involving the workforce allows better adoption.
And so you look at the
MIT study, there's sort of big headlight, flashing headlines.
"90% are failing.
" And then it's interesting because in that it actually
said that the ones that tried to build it themselves
were more likely to fail

[15:25]
than the ones that just bought a platform.
And then I kind of wonder, "Well, is that because they weren't under the
time crunch of a vendor, and therefore could take a longer view on it because it was in-house?
" So that's possible.
But I think, really, from talking to industry, they do want help.
They do want outside experts coming in and helping to advise them as to, well, what's worked well for others.
Some are waiting for
the larger companies to roll out agents.
But the way I look at that
is, why would I wait for the Salesforces or the
Oracles to have maturity?
Because all I'm doing is
allowing my competitors to have that same advantage.
And so I would move quick
and scale up from that.
And that's kind of our goal, is basically get an agent in place, have
it doing something useful, light up the eyes of the
workforce in terms of what the art

[16:28]
of the possible is and then
start rolling out more in that sort of fashion.
>> Yeah. I mean, I think that
this reflects the notion that it's changing from a
software automation market to a labor market.
Because if you do your agents, you can decouple them from
the SaaS applications in the infrastructure, and you can literally hire and fire based on performance.
So why wait around?
It's like I'm not going to
do anything new until...
It's just wait until... You wouldn't wait to hire humans, right?
And by the way, in one
of those 61 questions in our research survey
was about how do you plan to acquire AI agents.
And the least of all
were build it themselves.
I think it was acquire or
source. So it's platform vendors.
It's people that sell specialized agents.
It was systems integrators and consulting firms,
application providers.
But very, very small number,
I think it was in the teens, low teens, if I remember
correctly, were going to actually try to build themselves.

[17:29]
And I think that MIT study
reflects why you should probably not do that, right?
View it as you're going to
hire some digital workers is essentially what you're
going to do, right?
>> Exactly. Exactly. And then the whole...
I mean, I don't think organizations want to have 15 different agents
from 15 different companies.
I have to buy the SDR from this company.
I'm going to buy the
telephony from another.
And, basically, they have
that term agent sprawl where, basically, you've got so
many different agents doing different things, but they're
not talking to one another.
And you would never hire
a workforce like that.
You need your workforce to be able to communicate with one another.
So building it on an agent platform whilst you build it off the...
or buy it off the shelf, but then have a platform where at least the agents are in one place because I don't...
If I'm running an organization,
I don't want to have to go to 10 different platforms
to see what's happening

[18:31]
with those agents and
how their performance is.
You want to go to one or you
want to go to one or two.
And so that's why I think the agent framework platform
approach is much better because the observability's
in one place, the dashboards, just like if you were going
into an HR system to see how is your workforce doing
or you want to see payroll or whatever in terms of
outputs or hours used.
Same sort of thing, you know?
>> Yeah, no. I'm definitely
with you on that.
And it's sort of like
your digital HR department for being digital because you're hiring
digital workers to work with your human workers.
And that kind of brings us to investment.
So when we looked at the data where the dollars are
flowing in the survey...
And we did digital labor transformation.
We did agentic AI technology
adoption, decision intelligence and reasoning, trusting in
governance and compliance,

[19:33]
and we did causal AI.
But when you kind of step back and look at it, it seems
to me that it is flowing...
The biggest flow is into
the notion of AI reasoning and decision intelligence so that these things can make judgment-based tasks or be able to make decisions that are based on a judgment, which Gen AI and LMS cannot do alone because they're statistical models, right?
And so I'll show you a chart here.
I'd love to get your reaction
to one of the survey questions and hear what type of investments you're
seeing being most critical to unlocking the ROI in this space.
So here's the question on the right.
How would you describe
your organization's level of investment in AI reasoning and decision intelligence
over the next 18 months?
And we asked the same
question for all five of those categories I mentioned before.
This was the highest. 73% of enterprises are
planning either significant or strategic investments in enabling AI

[20:35]
agents that can reason.
That's big numbers if you follow surveys.
Anything that gets up into that range when you add those
together shows a major shift is underway in terms of where
investment's actually going.
Thoughts?
>> Yeah. No, I agree. I think, I mean, all of them are looking at
their existing tasks or the existing roles of
people within the organizations and seeing, "Well, how can we
apply AI to make it better?
" And you see CEOs of these
large companies coming up with these emails and letters, and lot of them get
leaked, of course, saying, "We're an AI-first company.
Before you even reach for a
spreadsheet, you need to go to ChatGPT and think about
building an agent to do it.
"
And it's so funny because, really, when you
look at any organization, it's a combination of systems and it's a combination of
spreadsheets on people's PCs that they're using today.
And so I think

[21:38]
these organizations are hip to that and they want, basically,
people to start thinking, "Okay, well, how do we automate the job function?
"
And so the money's probably flowing
mostly into less chat bots, more into knowledge worker tasks, right?
It's all about... You know, you look at the knowledge worker.
It's highly skilled, highly valued, very high judgment, et cetera,
but it's also very expensive.
And so I think they're laser
focused on that type of role.
And to your comment about
gen AI not being able to make judgments, et cetera, I think people and these LLM companies
have got very creative and there's a lot of good
papers out there in terms of the planning models and reasoning models

[22:39]
that basically iterates using
LLM in order to actually make very good judgments.
It is still a synthetic
judgment based on, yes, it's probabilistic and it's not deterministic.
But again, isn't human judgment
a little bit like that, depending on whether they
had a good Monday morning or it's a Friday?
>> Yeah, I think that's my
point is that generative AI, let's say LLMs alone,
I think, are incapable of making judgments.
>> Yeah. - What you're seeing
is enterprises in particular, but I think the LLM providers,
generative AI, will start to build that expanded
ecosystem on top of an LLM.
I think generative AI is just...
Just like the browser was a
gateway into the internet, I see generative AI as being a
gateway into the world of AI.
It's democratizing it for people to use, but it still is a
statistical model, LLMs are, that make predictions.
A prediction is not a judgment.

[23:41]
>> Right.
- And you need judgments to be able to make decisions.
And decisions are all about consequences.
And so I think what's happening, slowly but surely, people are
starting to build upon the LLMs as a foundation with these
extended capabilities.
I think you're doing this with
some of the automation stuff and learning capabilities.
And I think our survey also found that.
And even to your point, when you look at what people are looking to do with the agents as they
go forward in time here, their primary activities,
look at decision-making to assist in making better decisions.
62%, right?
And you can see it's surrounded
by being able to diagnose business problems, root
cause analysis, if you will, and being able to plan to achieve goals and things of that nature.
But 62% actually want these agents to help them make better decisions.
And that's where I think
this stuff is heading.
Because making decisions is

[24:41]
what knowledge workers do, to your point.
>> Yeah. Yeah. No, absolutely.
And we are seeing... I
feel like we may not have as many knowledge worker...
digital agents deployed
across the industry as organizations may want,
but we're getting there.
And the gap between good enough and not good enough
is shrinking every day.
And so I think the money
is flowing into R&D and flowing into a lot of trials and pilots, et cetera.
And even for the...
Take the example of the financial reporting agent that we built.
It's multi-staff.
It's giving the agent the
autonomy to be able to decide, "Well, where am I going to
get this information from?
" And when you run that...
I think that one's been running for about five-and-a-half months now.

[25:42]
You get to feel that it's reliable.
I call up the customer and say, "Well, how's the agent running?
Is it making any mistakes?
Is the output good enough?
Seen any anomalies?
" And they're saying,
"No, it's really fine.
" And that's what you want.
You need that sort of confidence in the agent in some- >> 100%.
>> And it's not a simple thing, but to you and me it seems simple.
But whenever you're asking it- >> That's because you've
extended the core LLM, right?
And with the automation
and the ability to learn and understand what was right and what wasn't right, it just gets better and better, as your point, I think, earlier about the monthly.
>> Yeah.
- And then you're seeing...
To your other point about them and the R&D and extending generative AI and the LLMs with things
like chain of thought, right?
>> Yeah.
- Then you got agentic RAG, which starts to provide a little bit of context.
Then you got MCP.
Then you got knowledge
graphs that provide semantics

[26:43]
and meaning and
relationships among entities.
And then I think that's
going to evolve into causal knowledge graphs that actually
understand cause and effect, and therefore consequences of different- >> Yes.
- ...
decisions that can be made.
And so I think there's
a progression of things that build layers on top of
the LLMs as the core gateway.
I think that's where it's all
heading to enable the kind of things we saw in the last chart.
Probably ways to go here, but I think you guys are
on a leading edge here of applying some of those technologies and certainly domain-specific
information to automation.
And that's why I think you're
having success with some of these things, is that
they're able to adapt and learn, right?
>> Yeah. Yeah.
- Within workflow.
>> No, exactly. I mean,
being able to go in...
When things do go wrong,
it's being able to go in, see the agent flow, right
click on the actual agent and see the decisioning
and the chain of thought or the planning that it undertook.
It comes up with a plan,
comes up with a goal.
And then you can see what steps it took to move itself towards the goal,

[27:44]
and then sometimes a call
fails or an API call fails, or it shows the wrong tool,
in which case then you have to go and tighten up the
agent in order to make sure that doesn't happen again.
But you need that ability to go in and see that at scale.
And then you get to a point
where you actually have...
You look at your agents, and you see a reliability percentage.
And you can see, "Okay, well,
99.9, is that good enough?
" And, obviously, it's
very low at the start.
And so we've built a lot of
those things into the platform, the things you're mentioning,
like RAG, the ability to add memory, and I think that's...
I'm seeing a lot more
noise about that now, because we think memory
is really important.
Because you might have
an agent do something for you, an ad hoc or on a repeated basis, but you then need to be
able to talk to the agent

[28:45]
and say, "How are we
doing this week in terms of sales performance versus last week?
" Right? And it needs to be
able to answer that question.
Because a person would. A
knowledge worker would be able to, say, answer questions
if a colleague asked it.
So that's what we're focused on as well, is basically adding that...
enhancing the agent memory
so it's both short term and long term so it has more context and able to add value
outside of the things that was originally envisaged for.
>> Yeah, that's why I love
talking to you because you have made a lot of progress here.
I'm going to show you another
question from the survey.
And at least half of them
you should go talk to because you've achieved people, human workers gaining confidence, having confidence in their agents, right?
>> Right. Yeah.
- You've been mentioning a couple examples of that.
But if you take a look at this question...

[29:46]
And this is where you get to
the notion that the currency of innovation is going to be trust, right?
No trust, no ROI.
Only 49% have a high degree of trust in these agents to make decisions.
So a little bit more trust for planning.
They think they can
really trust to build...
you know, solve problems
and stuff like that.
But when you start getting
into actual, "Do I trust it to help me make a decision?
" over 50%, let's just say half of them, don't have a very high degree of trust.
And this was AI professionals, and we asked the same
question from end users.
Ironically, end users were a
little bit more trustworthy or felt a little bit more trust.
I don't know whether it's
because they're not...
Maybe they think a lot of this stuff is working better than it is.
It seems to be a big gap.
But clearly this is the
overriding challenge, I think, these companies that are moving
into the world of agentic AI and digital workers have
to address, bar anything,

[30:47]
is going to be trust.
And that's not just a technology thing, it's a cultural thing, right?
>> Yeah. Because we've all seen
when you talk with ChatGPT or with Claude how
malleable it is in terms of its answer.
You could ask it something,
and it gives you an answer.
And then you say, "But
I was thinking it was this," and it goes, "Oh, you're right.
It is this." And you're like, "Well, you didn't stand by your original...
your decision. And I just
threw something at you, and now you change your mind completely.
"
And it's the same thing with agents.
You have to be very laser
focused about the context that an agent has available
to it in order to make sure that the agent's going to
make the right decision.
Otherwise, it's going to
be very non-deterministic.
It's going to change. There's
going to be high variability.
And another example of that is
sometimes when you're talking to LLMs and it's getting information
from the outside world, well, depending on where it's getting it from at that particular time, that
could influence the decision.

[31:50]
And so, again, it's the sort of thing when you're building
an agent to be truly agentic, you have to be very measured
about the way you expose the agent to external information.
And all of that are the things
that organizations grapple with to actually put it into production.
Because the last thing
you need is an agent that you can persuade it to bend
to your will, you know?
>> Right. Right, right. That just wants to appease you, right?
>> Yes. - A yes-man or a
yes-woman that just - >> If it's a loan officer...
Yeah. If it's a loan officer or a claims adjuster, then
that could be catastrophic.
>> Yeah. We think about
that's the difference between being an assistant, digital assistant, versus being a digital partner- >> Correct.
- ...
coworker where you're actually working with each other, right?
>> Yeah.
- So let me just show you another thing, because we're getting close to
time here, which is my view,

[32:50]
from what I learned in
this section of our survey, that brings together...
Basically, the top line message
here, right? So investment.
You can see we did these
maturity curves where you're able to rate from one...
or from zero to five where
you are on the maturity index.
So investment at 3.7, that's
actually ahead of the median.
And so I think there's a
rich amount of investment that is going into AI
reasoning, the technology, the strategies, the intent.
When you look at the use
cases around knowledge work, it drops off a little bit to 3.
1. I think people aren't
being quite as visionary as they could be or understanding
the capabilities that could be put to bear.
But that's pretty solid
still for early days.
But again, what we were
just talking about, Paul, the trust factor, it drops down to 2.
4 on the index.
So again, that's where
the focus needs to be

[33:53]
really on, is you got to
have trust in particularly among the people that are
going to be using these things.
Otherwise, no one's going to work with it.
If you don't trust a human
coworker, you're not going to work with that co-worker
very well either, right?
>> Exactly. Exactly. And
that's it. You just got to...
As you roll out agents, you've just got to start small, build upon the successes, gain adoption, and then
that trust will increase.
And so I think it'll be
very interesting to take that measurement again in six months' time and see how it's improved,
or hopefully it has improved.
Because I think we're very
early to this still, you know?
>> Yeah.
- And I think organizations are rightly being cautious.
So whilst a lot of the big
headlines will say that we're rolling out agents everywhere, and it might look as if,
my goodness, things are

[34:56]
steamrolling ahead, I think
that's more noise than reality.
And I think the organizations
that are quietly deploying agents that succeed and adopted, they're the ones
that ultimately are going to succeed in the long run.
>> Yeah, I think you're
a hundred percent right.
In probably the next
podcast, if not the one after that, I'm going to unveil
the agentic AI trust index, which was part of the survey.
And I think you're right.
This is the thing that has
to be nailed by companies.
You got to have the trust
not only in the accuracy and the outcomes if you're
making real business critical decisions, but the
people have to trust it.
And if the people don't trust it...
And by the way, just a
little bit of insight into what I learned in that survey,
I think the number one thing to do to make sure it's
trustworthy is get it to become more explainable and understand.
Explainability becomes really important

[35:57]
because people just tend to agree and go with things that can be explained to them so it makes sense.
These black boxes are not good because you're just
like, "It's telling me to potentially make this decision, but it's not explained to me very well why that's the right decision-" >> Yes.
>> "... and why is that
better than other possible decisions." Right?
>> Right. Right.
- And so we'll get into that in a future podcast.
So before we have to wrap here,
one last question for you.
What would be the bottom-line
advice you'd give people that are just getting
started over that 61% that are starting to deploy agents, and not just to automate tasks, but actually to pair up
with coworkers to help them?
As a knowledge worker, what's the key piece of advice you got?
And then two, just tell
us a little bit about where people can go
learn more about DoozerAI and actually get in touch with you.
>> Yeah, okay. Yeah.
So I think, again, my main
advice would be start small, but think big, but actually start.

[36:58]
And that also means rolling
out AI throughout the organization to your employees.
Get them thinking about
how to actually use AI.
Bring in some digital
workers for some quick wins.
Put in agents so people
start getting used to them.
And then, actually, maybe even do workshops within
your organization to sort of have ideas or hackathon-type things where people can start thinking about how to use agents within the
organizations to improve things.
So I think sometimes those sort of competitive workshops can
be fun and done the right way.
And I think, obviously, you
have to have someone allocated to think governance as you scale.
So always have one look on that.
And I think the other thing is...
So focus on the integration, not just the innovation as well.
You need to bring along all
of the capabilities within in-

[38:00]
house, and that involves
IT and involves business.
And so it's a real cross-functional thing.
So to learn more about DoozerAI,
you can go to our website, D, double O, Z-E-R .
ai. We're active on LinkedIn.
We put out videos.
And we regularly sort of engage with our constituents.
We're happy to do a demo with anyone on the back if
would love to see a demo of DoozerAI and what we've built and the problems we solve for companies.
We'd love to show it to you.
>> Yeah. I'll just say,
as a firsthand reader of all your posts, you..., I think I said up front, very insightful, very well-thought-out.
I learn a ton from you when I read your...
You're not just reiterating the hype and the marketing stuff.
You're taking your real-world experience and actually translating it
into things that people need to think about, which is great.
So I encourage you all
to go out into LinkedIn and follow Paul.

[39:02]
I think you'll learn a lot.
And, again, thank you for
being a part of this podcast.
Love the insights. Always
love our conversations.
Continuous learning is what
this is all about, right?
And I do every time I talk to you.
>> No, thank you, Scott. I think that...
I mean, all the insights have been...
It's great having the
index to understand exactly a measurement across the industry, and I'm looking forward to the next one and the other ones to learn how things are moving along. Thank you.
>> Yeah. Yeah. Nothing
better than data, right?
>> Exactly. Exactly. Yeah, that's right.
>> All right.
- Appreciate it.
>> You bet.
- Thanks, Scott.
>> And for our listeners, I think the takeaway is quite clear here, right?
Agentic AI is no longer really...
It's not a future vision.
It's unfolding right now.
And as we always say, the game is played on the
field, not in the dugout.
So be careful not to fall behind because you may never catch up
with these innovation cycles moving so quickly.
And I think the new game is
going to be around reasoning and decision intelligence being
infused into these agents, and then nailing this notion of trust among the actual users.

[40:04]
If you would like to explore
the Agentic AI Futures Index survey data in more detail or leveraging of these insights
to help drive your strategy or market impact, I welcome
the opportunity to connect with you directly.
You can reach me at
@ScottHebner on LinkedIn or scott@siliconangle.
com. Hope to hear from you.
And don't forget to subscribe
to the Next Frontiers of AI podcast so you don't
miss future episodes.
Until next time, I'm Scott Hebner.
Thanks for being a part
of today's podcast.
We'll see you real soon. Bye for now.

---

*Content extracted from YouTube video. Original content by SiliconANGLE theCUBE. Video URL: https://www.youtube.com/watch?v=PH6KNZykjX4*