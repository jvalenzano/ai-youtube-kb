# 7. The Anatomy of a Decision-Making Agent | The Next Frontiers of AI

**Video ID:** iHROZ526tUg
**Channel:** SiliconANGLE theCUBE
**Duration:** 26:08
**URL:** https://www.youtube.com/watch?v=iHROZ526tUg

**Module:** Foundations of AI Agents
**Module Rationale:** This video provides foundational conceptual frameworks for understanding AI agents, decision intelligence architecture, and the progressive technology stack needed to build decision-making capabilities

## Summary
- AI agents build upon AI assistants by adding goal pursuit, problem-solving, and decision-making capabilities, while agentic AI networks multiple agents together for organizational workflows
- Future decision-making agents need to understand causal chains, explain consequences of actions, enable what-if scenarios, and provide explainable reasoning for their recommendations
- LLMs and generative AI alone are insufficient for decision intelligence as they operate on correlation rather than causation and cannot make judgments based on consequences
- Building decision intelligence requires a progressive four-step approach: domain knowledge, semantic reasoning via knowledge graphs, causal reasoning, and multi-agent orchestration
- Chain of thought reasoning, semantic reasoning with knowledge graphs, and causal reasoning represent increasing levels of sophistication in agent decision-making capabilities
- Causal AI is emerging as the critical technology for enabling true decision intelligence, with 70% of AI professionals expected to be involved with causality by 2026
- Agent sophistication tiers progress from domain intelligence (prediction) to semantic reasoning (context) to causal reasoning (what-if scenarios) to planning/orchestration agents
- The technology progression moves AI from correlations to reasoning, predictions to decisions, tasks to goals, and black boxes to explainable systems that build trust

## Key Takeaways
- **DO:** Build decision intelligence progressively: start with domain knowledge, add semantic reasoning via knowledge graphs, then causal reasoning capabilities
- **DO:** Focus on causal AI technologies like causal knowledge graphs and CausalRAG to enable true decision-making rather than just prediction
- **DO:** Ensure agents can explain the how and why of decisions, as people only trust what they understand
- **DON'T:** Rely solely on LLMs and generative AI for decision-making agents, as they lack causal reasoning and consequence understanding
- **DON'T:** Confuse prediction capabilities with decision-making - predictions are correlative while judgments require understanding consequences

## Topics
AI agents, decision intelligence, causal AI, agentic workflows, knowledge graphs, semantic reasoning, causal reasoning, multi-agent systems

## Key Moments
- [02:03](https://www.youtube.com/watch?v=iHROZ526tUg&t=123s): Defines the progression from AI assistants to AI agents to agentic AI systems
- [05:08](https://www.youtube.com/watch?v=iHROZ526tUg&t=308s): Outlines four key capabilities future decision-making agents must have
- [08:14](https://www.youtube.com/watch?v=iHROZ526tUg&t=494s): Introduces the AI model ecosystem concept with specialized models under the waterline
- [16:27](https://www.youtube.com/watch?v=iHROZ526tUg&t=987s): Details the four tiers of agent sophistication from domain intelligence to orchestration
- [21:32](https://www.youtube.com/watch?v=iHROZ526tUg&t=1292s): Presents data showing the hockey stick growth in causal AI interest and adoption

## TL;DR
Building trustworthy AI agents requires progressive integration of causal reasoning beyond correlation-based LLMs.

## Full Transcript

>> Hello everyone.
Scott Hebner here. I really
appreciate you joining me for this episode of the Next
Frontiers of AI podcast.
Over the last seven weeks, we have featured industry
pioneers that are helping to shape the future of AI.
That included BMW, Fitch
Ratings, Scanbuy, Geminos, G2, and we were able to hear
from them their visions of what's going to
happen as we go forward.
It was all anchored in AI agents that can actually make
trustworthy decisions.
As a result, I have
received a ton of interest and a bunch of input and feedback and even many questions on how to go about building decision
intelligence into AI agents.
So today I'm going solo.
I'm going to try to outline
here my point of view from what I've learned from
these industry pioneers and other experts, and
frame it within a strategic

[01:01]
approach on how to enable decision
intelligence in these agents.
Basically, a summary of what
is needed to create AI agents that can actually, truly make decisions and those decisions are
trustworthy and explainable.
So let's do it. Let's
jump right into it here.
Obviously it starts with
what I think is a lot of discussion out in the
marketplace as I watch it, how do you actually define an AI agent?
What I've learned from the
people I've been talking to, you can see the chart here,
is this sort of progression.
We're all accustomed to AI assistance.
They are fueled by LLMs and generative AI.
They're really good at being
able to automate simple tasks, repeatable tasks.
They can analyze information for us, they can create content.
When they're connected up to
predictive models, they're able to make predictions.
A lot of value. We've seen this
happening over the last two

[02:03]
to three years, and it has
really changed the landscape of what companies are
trying to do in their IT and digital business efforts.
This year in 2025, we're seeing the rise of AI agents in Agentic AI.
An AI agent, in my view,
builds upon an assistant to actually be able to pursue a goal, to help people problem solve, and to actually make decisions.
This is where the rise of decision intelligence
becomes critically important.
Then Agentic AI is when you're able to take multiple agents and wire them together into
a framework, into a network or a system, and collectively
they can plan action paths and orchestrate workflows that involve not just an individual but an entire organization, and they're able to
take autonomous actions to help move things forward.
More of an organizational approach to leveraging agents versus AI agents

[03:05]
that perhaps maybe just for an individual.
This is how I've interpreted what I've been hearing
out in the marketplace.
I'd be really curious to what you think and what you're hearing out there, because clearly without a
definition, everyone's going to start to call everything an AI agent and everything's going to be Agentic AI, and then we're going to
lose the differentiation.
But let me go onto the next view here, is what is a decision-making
agent actually do?
And more importantly is, what
does the future look like?
This may not be this year,
it may not be next year, it may not be the year after.
On the other hand, it could be.
But what we need is agents that can help humans understand
the precise chain of events that leads to a desired outcome.
They're going to need to
know why things happen.
They're going to need to
understand consequences of various actions

[04:06]
or decisions that they're
going to recommend, and how do they know which one is the best among multiple options.
They're going to need to
help people actually engage and interrogate the agent,
to ask what-if questions, to discover how does my
business actually operate?
What are the causal effects
on different actions, different conditions, different interventions that I can make?
How does that change an outcome?
What are the root causes of
a particular problem I have?
What happens if I do
counterfactual analysis and I can say, "Well, look, I'm going to change the inflation
rate in Switzerland to this, and I'm going to change
the bond projection in the United States to that.
What is that going to do
to the overall bond market?
" For example. These agents
are going to need to be able to interact with humans
to do what-if scenarios and to simulate different
hypothetical approaches to solving a problem.
Then perhaps most importantly,
given those three things, is it's going to have to
be able to explain the how

[05:08]
and the why of the decision or an action.
Because people are only going
to trust what they understand, and the only way they're going
to understand why something is worth doing, is if the
agent can actually explain to the human why this is
the right approach to take.
I think this represents a snapshot of some time in the future
what we should be striving for in terms of creating
decision intelligence agents.
Now, another thing that
I've really learned and has become crystal clear
from all my discussions is that generative AI and LLMs alone are insufficient
in creating AI agents, I think in general, but certainly decision intelligence-based agents.
Why is that? Well, first of all, they operate on correlation.
They're correlative in design
where they're crunching through huge, massive lakes of data, and they're essentially
identifying statistical probabilities that create patterns and correlations among different
parts of the data set, and

[06:11]
therefore are able to
make a prediction for what may happen in the future based on what has happened in the past.
But predictions are not judgments,
and a judgment is needed.
Judgment is basically
based on consequences.
When you make a judgment,
you're thinking through what are the consequences
of different potential paths forward, right?
It's consequences that then
inform how you make a decision.
Then of course, as we said before, a decision must be explained.
So generative AI and LLMs have created
a critical foundation.
I equate them to the browsers
of their early internet age, where the browser created a
gateway into the internet.
The value came over time
as people built around and on top of those browsers
to create all new kinds of innovations and business value.
I think the same thing's
happening here with generative AI and LLMs, they become
part of the foundation, they create a gateway
into the world of AI,

[07:12]
but the value will come
on how you build around and on top of the LLMs leveraging
the generative AI services to address these problems, these limitations is
probably a better word.
Because if you don't,
the agents won't be able to explain themselves,
they won't be able to adapt to changing conditions.
They're certainly going
to be prone to bias and inaccuracies.
With no notion of consequence,
they're not going to be able to have a discussion
with you, if you will, on what the right approach is.
That includes doing
counterfactual analysis.
They're just simply insufficient to be able to do this alone.
It's my strong belief that
if you look under the tip of the iceberg, under the water,
if you will, of what needs to be created to fuel these
agents, it's going to be powered by an AI model ecosystem
that equips agents with domain knowledge, with
reasoning capabilities, with explainability, all
within a unified framework.

[08:14]
It's taken LLMs and generative
AI and complementing it and extending it with these
extended specialized models.
That's going to become what's going to be under the water line,
if you will, of the iceberg.
Above the water line being the agents and how they're wired together
into Agentic frameworks.
That's what we're starting
to see be built out in numerous businesses.
There's vendors that
are coming on the scene with new innovations, and
we've heard from a lot of them over the last many
weeks here on this podcast.
T. Hat brings us to the journey and how do you go about
building this ecosystem?
When you look at the chart
here, it starts, as I said, with your foundation,
generative AI services and the LLMs.
Step one is, you need to have
domain specific knowledge.
Whether it be for how you process legal precedent
when you're doing contracts,

[09:16]
or whether it is about customer service or it's about clinical drug
trials, you have to have that domain intelligence that extends the more
generalized knowledge that are in the LLMs.
That's step one. The second step is, you need semantic knowledge
or semantic reasoning.
That's where knowledge graphs
come in, for example, so that you understand the relationships between entities in a problem set.
It helps you understand
the context of the problem or the decision that you're
thinking about, as well as the meaning on how one
thing relates to another.
Again, that's another step
in the progression here of creating more and more reasoning and therefore decision intelligence.
From there, you need to build
into, what I'm referring to here as causal reasoning,
distinct from semantic.
Because causal reasoning
understands the cause and effect mechanisms
across a system of decisions and sub-decisions.

[10:16]
Think of it as a causal knowledge graph that not only has the entities and the relationships among the entities, but it also can tell you the cause and effect among those entities.
And if you change variables in one place, how does it affect variables in another?
And if you make a decision
in one part of the graph, how does it affect a decision's being made somewhere else in the graph?
Just like human beings, everything
we do, for the most part, almost everything we do
involves causal reasoning.
We think about cause and effect in almost everything that we do.
As I've said in past podcasts,
when the alarm clock goes off and it's like, "Do I hit
snooze or do I just get up?
" You're immediately thinking
about the pros and cons or the cause and effect of
whichever decision I make.
AI is going to need to be able to do that.
Then I think the ultimate power, at least over the next
many years, is going to be when you start taking those models and you're able to wire them together and wire agents into a network

[11:18]
or a system where they act
like swarm intelligence.
Where they may all have specialties but they learn from each other and they're able to
collectively make decisions.
I think this is the roadmap
that we're on into the future, and as we move down this roadmap, you get into more progressive ability to actually make trustworthy
decisions from an AI point of view.
All right. Let's just
dive a little bit deeper into these technologies,
just to give you a little bit of insight into how this comes to life.
Again, this is what I've pieced together all
the conversations I've had.
When you think about these
decision intelligence type of technologies, I think
 number one, step number one, if you
will, is chain of thought.
You see this first in the OpenAI, ChatGPT, I think it was 4.0 or 4.

[12:18]
0 mini or one of the two, that first came out with chain of thought.
Where it's still correlative in nature, but it's able to think about
what it's doing, go backwards and rethink things.
It learns better.
It's a little bit more
of a thoughtful approach to coming out with a correlated outcome.
Because basically it's breaking
the problem into logical steps that are then dynamically evaluated and revisited until you
get to a desired outcome that you think is right.
There's other things that are
added into this like attention transformers, and there's
reinforcement learning with human feedback, not
only at the model level, but also at the token level, if you will.
So it's a very sophisticated
set of technologies that take a major step forward.
I think it's very important
in the progression of decision intelligence.
Step two, as we said before,
is semantic reasoning.

[13:21]
This is where you're able
to interpret the underlying context and relationships and the concepts in a much
more logical manner of how entities relate to each other.
Things like workflows or a customer record is
related to a service call, which is related to the
product that they bought, which was related to what part
of the country they bought it and so on and so forth.
That's where knowledge graphs
become really important.
You're seeing more and
more people using GraphRAG, which can keep those knowledge graphs up to date in learning.
You're even seeing symbolic
AI that merges neural networks with knowledge graphs that
can actually deal with more complex problems, and it's able to sort
of learn the knowledge graphs in real time as it learns.
That's given you the semantic reasoning.
Causal reasoning, this is
where you're able to understand how and why things actually happen

[14:21]
and the consequences of actions.
Simply put, cause and effect.
There's new technologies out
there like we talked about last week with Stuart Frost from Geminos, a causal knowledge graph.
It's an advancement of the knowledge graph that then builds in the causal effects.
There's CausalRAG that operates in a very
similar way to GraphRAG.
It allows you to integrate LLMs and generative AI into
your causal knowledge graph to not only build it in the first place, but to inform the LLM
about the causal learnings and it creates a circular learning loop.
Then I even think you're
going to start to see, and I know there's a lot of
research going on in this space, but this notion of a
causal neural network.
That again, fuses a causal knowledge graph with a neural network that gives you another
level of sophistication.
This is all happening today.
There's tons of vendors out there today

[15:23]
that provide these solutions, and I think it's going to become more mainstream as we go through time here.
Then finally, as I said before, how do you wire these things together to have even a higher degree
of decision intelligence, swarm, if you will.
That's where you get into multi-agent RAG.
You get into limitation
reinforcement learning, where you're imitating the
outcomes that other agents or models were able to accomplish, and the notion of swarm
intelligence or swarm AI.
A lot of these technologies are out there and there's some people
that have implemented them.
They're going to become more
and more mainstream as we go through time here, as
they get democratized by different vendors in the marketplace.
Let's translate that
into the world of agents.
I've pulled a chart together here that basically outlines the
tiers of sophistication, very high level obviously.
But if you think of a
domain intelligence agent that understands the specific
domain, like legal precedent

[16:27]
when doing contracts, it acts based on what has happened in the
past and what it has learned.
It can help you automate
how you make a decision in that case and give you
the information you need.
It's going to recognize
patterns and anomalies.
It's going to help you basically predict and forecast what may happen, given what has happened in the past.
In this case, on the bottom in blue, you can ask a question like,
"What is the primary driver of customer attention?
" And it'll be to predict what that primary driver is, and it can usually do
it with good accuracy.
But predicting it is very
different than understanding why it happened, what the
root cause of it was, and how do I improve it.
That starts getting you to the
next level of sophistication, which is a semantic reasoning agent.
Again, that agent's going to
act on semantic structures and contextual knowledge of a problem set.

[17:28]
So it's going to be able
to navigate these entities and the relationships among them.
It's going to be able to help the human or the business understand context and meaning of the decision
they're trying to make.
It's going to understand the ontology of the actual organization
or of some knowledge set.
In many cases, it starts to
infuse in expert know-how, like how to go about writing a contract or how to go about keeping
customers and retaining them.
An example there would be not just asking what the primary driver is, but asking how does the
newsletter influence customer retention?
Now it can actually tell
you semantically, "Yes, I now know that the primary drivers of customer retention is
getting the newsletters and being kept up to date, but how and why is that newsletter influencing

[18:30]
this better retention?
" So it gives you another step in the decision making process.
Then a causal agent that
can reason with cause and effect, then is able to act on basically reasoned decisions.
They're going to be able
to infer the consequences of different potential action paths.
This is where you start to get to true decision intelligence.
Because you have
interactive explainability, you have interactive capabilities
to do what-if scenarios and do counterfactual
analysis and ask it what if.
The example here being, "What happens if we then
increase the send rates for the newsletter by 20%?
Will that further increase
customer retention?
" And it'll be at a model out.
Or if you say, "What
happens if I do it 10% more?
Or what happens if I send
out fewer newsletters?
" You're going to be able
to do the what-if scenarios.
Or what happens if you were to
change some of the conditions

[19:30]
of how the newsletter
looks, how it gets received, what time it gets received.
That's counterfactual sort of reasoning.
You can do all that stuff
with a causal agent and therefore it's going to help
you really decide what to do because you're going to
understand the consequences of different potential actions.
Then finally, the planning and orchestration agents, those
are the ones that know how to plan, they know how to coordinate the intelligence across
multiple agents in a workflow.
It's going to be able to
tap into the specialization of different agents.
This is where you start to
get contextual perception of a bigger environment that the agent's trying
to make a decision in.
Not just if I send a newsletter out, but what other interventions will reduce the loss of customers?
Give me some ideas of what
other things I can do.
This is where it works a
little bit more autonomously.
It goes out, the agents do their work.

[20:31]
It can have dynamic pathways and a whole bunch of different ones where they're playing off each other and where one decision in one
place will affect decisions in another place of the workflow.
It's like indirect multi-hop reasoning, but with real causal
reasoning under the covers.
That's how I see all this
over time, creating more and more sophisticated AI agents that ultimately get wired together into these Agentic frameworks.
One more point here, which you can see where this is all leading.
I do think over the next
couple of years, this idea and this emerging
technology around causal AI, that's the secret sauce or the secret ingredient that's going to really progress decision intelligence.
We're tracking here at theCUBE Research 20 or so vendors that are actively
providing solutions today that help businesses infuse
causal reasoning or cause

[21:32]
and effect or causal knowledge graphs.
All the big guys out there and name it, OpenAI, Meta, IBM, there's a bunch of them out
there that are doing a ton of research and development in this area.
The bottom line though is,
if you just look at the progression of interest here.
Back in 2022, very little
search, very little interest in causal AI, but you can see how it's really ramped up
over the last several years and is really starting to
turn into a hockey stick.
Because people are
starting to realize that to make decisions, you
got to make judgments, to have judgments, you need to
understand cause and effect.
Therefore, AI is going to have to slowly but surely build that kind of capability.
What's nice about this, it's not rip and replace, it's a
progressive technology roadmap where you're building
upon the previous layer.
You have LLMs and generative AI, then you
have the knowledge domain

[22:34]
models, and then you infuse
the knowledge graphs, and then you have the
causal knowledge graphs.
It's progressive. A survey that Data IQ and Databricks did, I think
it was a couple of years ago, you can see the numbers here.
There were 16% of 400 AI professionals that were actively using
causal AI already, another 33% that we're experimenting and 25% that plan to evaluate.
So by the end of 2026, at
least this survey estimates, seven out of 10 will be
involved in the notion of causality and AI.
Which again, I think becomes
really important if you want to be able to enable these decision intelligence-based agents.
That's where I think this is all going.
There's just no doubt in my mind here.
It's what's going to allow
us to move from correlations

[23:35]
to reasoning, from predictions
to decisions, from tasks to goals, from black
boxes to explanations, and really from fear to trust.
I think trust is the
currency of innovation.
The more sophisticated the
AI gets, the more it is able to actually do, the more
trust becomes important.
Because people aren't going
to just blindly trust an agent to make a decision, not only because people only trust
what they understand for the most part, but there's
regulatory requirements and all those kinds of things that become really important here.
We'll see where this all
heads into the future.
I'm excited about it, and I'm looking forward to hearing more and more from our pioneers
that will be on these podcasts.
I would love to hear from
you guys on LinkedIn, or you can leave some
comments here, really trying to shape a point of view here on what's really going to happen.
In addition to that,
please mark your calendars for April 16th.

[24:35]
We will be hosting an industry
unique summit featuring industry pioneers discussing how to build AI agents in agentic systems.
Which of course will include tips and techniques on how
to create these agents that can actually make decisions, as well as everything else you'll
need, like domain models and pre-built agent marketplaces
in agentic frameworks.
So I hope you'll join us.
Please contact me on
LinkedIn if you would like to learn more about the summit, because it's coming up quick.
All right, well, it's time to wrap up.
I really appreciate you taking the time to join us here on the Next
Frontiers of AI podcast.
I so appreciate you being here.
Please let me know, again, what you think.
I'm trying to take in
as many inputs as I can.
Stay tuned for more research and analysis from our team as we dive deeper into
what's shaping the future of AI in business.
Visit us at thecuberesearch.com,
siliconangle.
com to stay connected and to
access all of our research

[25:38]
and podcasts from across the team.
We are the leader in
tech news and analysis.
Bye, until next time.